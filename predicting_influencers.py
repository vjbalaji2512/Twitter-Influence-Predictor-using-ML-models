# -*- coding: utf-8 -*-
"""sma-project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nPcdqYhdq2z_9ODfzcze_31X9MgkmthJ
"""

!pip install tweepy==4.9.0

# Commented out IPython magic to ensure Python compatibility.
from logging import warn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
# %pylab inline
import seaborn as sns
from pandas import read_csv
from matplotlib import pyplot

import nltk
from nltk.corpus import stopwords
from tweepy import Stream
from tweepy import OAuthHandler
import json
import tweepy
from collections import defaultdict
import time
import pandas as pd
from nltk.tokenize import TweetTokenizer
import random
from nltk import sentiment
from nltk import tokenize 
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import string
import gensim
from gensim import corpora, models
from nltk.stem import PorterStemmer 
from nltk.tokenize import word_tokenize
import warnings
warnings.filterwarnings("ignore")

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import sys
drive.mount('/content/drive/')
# %cd /content/drive/Shareddrives/sma-project/freezed-code/

# Load data 
Data_Train = pd.read_csv("data/train.csv")
Data_Train.head()

Data_Train.info()

Data_Train.describe()

print("Any missing values in the dataset:", Data_Train.isnull().values.any())

# Testing the correlation 

A_correlation = Data_Train .iloc[:,1:12].corr(method = 'pearson')
A_correlation

ax = sns.heatmap( 
    A_correlation, 
    vmin=-1, vmax=1, center=0, 
    cmap=sns.diverging_palette(20, 220, n = 200),
    square=True,
)
ax.set_xticklabels(  
    ax.get_xticklabels(), 
    rotation=45, 
    horizontalalignment='right'
)

B_correlation = Data_Train.iloc[:,12:23].corr(method='pearson')
B_correlation

ax = sns.heatmap(
    B_correlation, 
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n = 200),
    square=True,
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
)

"""To prepare the dataset for machine learning models, the dataset is divided into Test data and Train data. By creating a train and test split of your dataset helps in quickly evaluating the performance of an algorithm on your problem. The training dataset is used to prepare a model, to train it and the test dataset is new data where the output values are withheld from the algorithm. Transforming A and B individuals into A-B variables for better interpretation of the model.For the test data, values are selected from the data. For the train data, one variable is chosen to build the model. Here, the model is built upon the variable "choice". 

"""

x = pd.DataFrame(Data_Train.iloc[:,1:10].values - Data_Train.iloc[:,10:19].values)
x.columns = ['A/B_follower_count','A/B_following_count','A/B_listed_count','A/B_retweets_received',
             'A/B_mentions_sent','A/B_retweets_sent','A/B_posts','A/B_network_feature_2','A/B_network_feature_3']
y= Data_Train['Choice']

from sklearn.model_selection import train_test_split

x_train , x_test, y_train, y_test = train_test_split (x, y, test_size = 0.30, random_state = 42)

"""Looking at the shape of the data to test whether training features number of columns match testing feature number of columns.The number of rows to match for the respective training and testing features and the labels

"""

print('X_Train Shape:', x_train.shape)
print('Y_Train Shape:', y_train.shape)
print('X_Test Shape:', x_test.shape)
print('Y_Test Shape:', y_test.shape)

"""Spot Check Algorithms"""

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold


models = []
models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(("RF", RandomForestClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC(gamma='auto')))
models.append(('Xgboost', XGBClassifier()))

# evaluate each model in turn
results = []
names = []
for name, model in models:
    strat_kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
    cv_scores = cross_val_score(model, x_train, y_train, cv = strat_kfold, scoring='accuracy')
    results.append(cv_scores)
    names.append(name)
    print('%s: %f (%f)' % (name, cv_scores.mean(), cv_scores.std()))

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.feature_selection import RFE
 

model_logreg = LogisticRegression()
rfe = RFE(model_logreg,n_features_to_select=9)
rfe = rfe.fit(x_train, y_train.values.ravel())
print(rfe.support_)  #Indicates all variables have been selected by RFE with a ranking of 1 
print(rfe.ranking_)

import statsmodels.api as sm

model_logit = sm.Logit(y,x)
result = model_logit.fit()
print(result.summary2())

"""Removing variables with p-values greater than 0.05 to improve the model """

columns_to_keep = ['A/B_follower_count', 'A/B_retweets_received', 'A/B_mentions_sent', 
                   'A/B_network_feature_2', 'A/B_network_feature_3']
x = x_train[columns_to_keep]
y = y_train 

model_logit = sm.Logit(y,x)
result = model_logit.fit()
print(result.summary2())

# Logistic Regression Model Fitting 

model_logreg.fit(x_train, y_train)

# Predicting test results 

y_pred_logreg = model_logreg.predict(x_test)

# Calculating the accuracy of our model 

print("Training accuracy of Logistic Regression model:", model_logreg.score(x_train, y_train))
print("Testing accuracy of Logistic Regression model:", model_logreg.score(x_test, y_test))

# Confusion Matrix 

from sklearn.metrics import confusion_matrix, classification_report

confusion_matrix = confusion_matrix (y_test,y_pred_logreg)
print(confusion_matrix)

# Classification report will summarise our model by computing precision, recall, f-measure and support 

print(classification_report(y_test, y_pred_logreg))

# Random Forest Classifier 

from sklearn.ensemble import RandomForestClassifier

model_rf = RandomForestClassifier()
model_rf.fit(x_train, y_train) #Train the model on training data 

# Predicting the test results 
  
y_pred_rf = model_rf.predict(x_test)

# Calculating the accuracy of our model  

print("Training accuracy of Random Forest model:", model_rf.score(x_train, y_train))
print("Testing accuracy of Random Forest model:", model_rf.score(x_test, y_test))

# To interpret the model and report the results, feature importances is used to quantify how much a particular variable improves predctions 

feature_importances = pd.DataFrame(model_rf.feature_importances_,
                          index = x_train.columns, 
                          columns = ['importance']).sort_values('importance', ascending = False)
feature_importances

# Select features with importance larger than 0.08 

columns_to_keep = ['A/B_mentions_sent', 'A/B_listed_count', 'A/B_follower_count', 
                   'A/B_network_feature_3', 'A/B_retweets_sent', 'A/B_posts']

x = x_train[columns_to_keep]
y = y_train 

model_rf = RandomForestClassifier() #New random forest classifier for the most important features 
model_rf.fit(x_train, y_train) #Train the model on training data 

# Predicting the test results 

y_pred_rf = model_rf.predict(x_test)

# Calculating the accuracy of the model 

print("Training accuracy of Random Forest model:", model_rf.score(x_train, y_train))
print("Testing accuracy of Random Forest model:", model_rf.score(x_test, y_test))

# Confusion Matrix 

from sklearn.metrics import confusion_matrix, classification_report

conf_matrix = confusion_matrix (y_test,y_pred_rf)
print(conf_matrix)

# Classification report will summarise our model by computing precision, recall, f-measure and support 

print(classification_report(y_test, y_pred_rf))

"""K-Nearest Neighbors"""

from sklearn.neighbors import KNeighborsClassifier

model_knn = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')
model_knn.fit(x_train, y_train)

y_pred_knn = model_knn.predict(x_test)

# Calculating training and testing of our model

print("Training accuracy of K-Nearest Neighbors model:", model_knn.score(x_train, y_train))
print("Testing accuracy of K-Nearest Neighbors model:", model_knn.score(x_test, y_test))

# Confusion Matrix 

from sklearn.metrics import confusion_matrix, classification_report

confusion_matrix = confusion_matrix(y_test, y_pred_knn)
print(confusion_matrix)

# Classification report will summarise our model by computing precision, recall, f-measure and support 

print(classification_report(y_test, y_pred_knn))

"""XGBoost Classifier """

from xgboost import XGBClassifier
from xgboost import plot_importance

model_xgb = XGBClassifier(max_depth = 2, 
                          objective = 'binary:logistic',
                          eta = 0.3
                         )
model_xgb

model_xgb.fit(x_train, y_train)
print(model_xgb)

y_pred_xgb = model_xgb.predict(x_test)

# Calculating training and testing of our model

print("Training accuracy of XGBoost model:", model_xgb.score(x_train, y_train))
print("Testing accuracy of XGBoost model:", model_xgb.score(x_test, y_test))


plot_importance(model_xgb, max_num_features=9)
pyplot.show()

# Select the top 5 features and re-run the model 

from sklearn.metrics import confusion_matrix, classification_report

cols = ['A/B_follower_count','A/B_network_feature_3','A/B_listed_count',  
        'A/B_network_feature_2','A/B_retweets_received' ]
x = x_train[cols]
y = y_train 


model_xgb = XGBClassifier() #New xgb classifier for the most important features 
model_xgb.fit(x_train, y_train) #Train the model on training data 

#Predicting the test results

y_pred_xgb = model_xgb.predict(x_test)

plot_importance(model_xgb, max_num_features=5)
pyplot.show()

# Calculating the accuracy of the model 

print("Training accuracy of XGBoost model:", model_xgb.score(x_train, y_train))
print("Testing accuracy of XGBoost model:", model_xgb.score(x_test, y_test))

# Confusion Matrix 

from sklearn.metrics import confusion_matrix, classification_report

confusion_matrix = confusion_matrix(y_test, y_pred_xgb)
print(confusion_matrix)

# Classification report will summarise our model by computing precision, recall, f-measure and support 

print(classification_report(y_test, y_pred_xgb))

"""# Testing on twitter Dataset"""

consumer_token = "lOmeAKPROZCtQiMqL7uQpBpQ8"
consumer_secret = "gBzgztuzMstk5o3oGUdYgaTNL8gp9jeszu1ywyKmlLj51RiQrn"
auth = tweepy.OAuthHandler(consumer_token, consumer_secret)
api = tweepy.API(auth, wait_on_rate_limit=True)
if (not api):
    print ("Can't Authenticate")
    sys.exit(-1)
else:
    print ("Scraping data now")

def collect_tweets(until_date):
  input_queries = ['#ElonMuskTwitter']
  seen = {}
  dataset = []
  for input_query in input_queries:
      print(input_query)
      q_dataset = []
      for i, tweet in enumerate(tweepy.Cursor(api.search_tweets, q=input_query, lang="en",until=until_date, tweet_mode="extended").items()):
          datum = {
              "id": tweet.id,
              "username": tweet.user.screen_name,
              "name": tweet.user.name,
              "user_followers_count": tweet.user.followers_count,
              "user_listed_count" : tweet.user.listed_count,
          }
          q_dataset.append(datum)
          if (i + 1) % 1000 == 0:
                  print("processed {} tweets: saved {}".format(i + 1, len(q_dataset)))
      dataset.extend(q_dataset)
  return dataset

dataset = collect_tweets("2022-05-08")
dataset.extend(collect_tweets("2022-05-01"))
dataset.extend(collect_tweets("2022-05-23"))
df = pd.DataFrame(dataset)
df.shape

"""Filtering the dataset"""

df = df.drop_duplicates(subset='username', keep="first")
df.shape

df.to_csv("data/users.csv", sep='\t')

df.describe()

df["user_followers_count"].mean()

import matplotlib.pyplot as plt
# for user in df.iteritems():
followerCountFilteredDf = df[df["user_followers_count"]>df["user_followers_count"].mean()]
followerCountFilteredDf = followerCountFilteredDf.sort_values(by=['user_followers_count'],ascending=False)[:20]
# followerCountFilteredDf = followerCountFilteredDf.head(5)
plt.rcParams["figure.figsize"] = (20,5.5)
plt.bar(followerCountFilteredDf.name,  followerCountFilteredDf.user_followers_count, color ='blue',
        width = 0.4)
plt.xlabel("User Name")
plt.ylabel("user_followers_count")
plt.xticks(rotation='vertical')
plt.title("User Name vs User Followers Count")
plt.show()

import matplotlib.pyplot as plt
# for user in df.iteritems():
listedCountFilteredDf = df[df["user_listed_count"]>df["user_listed_count"].mean()]
listedCountFilteredDf = listedCountFilteredDf.sort_values(by=['user_listed_count'],ascending=False)[:20]
plt.rcParams["figure.figsize"] = (30,5.5)
plt.bar(listedCountFilteredDf.name,  listedCountFilteredDf.user_listed_count, color ='blue',
        width = 0.4)
plt.xlabel("User Name")
plt.ylabel("user_listed_count")
plt.xticks(rotation='vertical')
plt.title("User Name vs User Listed Count")
plt.show()

combined_df = pd.merge(listedCountFilteredDf, followerCountFilteredDf, how='inner', on=['username'])
combined_df.name_x

for i, user_c in combined_df.iterrows():
  filtered = filter(lambda user: user["username"] ==user_c.username, dataset)
  tweets = list(filtered)
  print("---------------------------------------------")
  print(user_c.name_x)
  print("Number of tweets:",len(tweets))
  print("Number of follower count:", user_c.user_followers_count_x)
  print("Number of listed count:", user_c.user_listed_count_y)